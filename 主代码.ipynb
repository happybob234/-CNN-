{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.29980635644\n",
      "=== epoch:1, train acc:0.213, test acc:0.23 ===\n",
      "train loss:2.29729393932\n",
      "train loss:2.29386630534\n",
      "train loss:2.28836010959\n",
      "train loss:2.27856351127\n",
      "train loss:2.2679577897\n",
      "train loss:2.25443243214\n",
      "train loss:2.24132177671\n",
      "train loss:2.21452264487\n",
      "train loss:2.19637812597\n",
      "train loss:2.15885371519\n",
      "train loss:2.13769859107\n",
      "train loss:2.07918464233\n",
      "train loss:2.04637927361\n",
      "train loss:1.9864605062\n",
      "train loss:1.92023449763\n",
      "train loss:1.85524198689\n",
      "train loss:1.78702710144\n",
      "train loss:1.78485712661\n",
      "train loss:1.6701855245\n",
      "train loss:1.44702142243\n",
      "train loss:1.42553549291\n",
      "train loss:1.36450634409\n",
      "train loss:1.34722917559\n",
      "train loss:1.15621129076\n",
      "train loss:1.2060189105\n",
      "train loss:1.1437482504\n",
      "train loss:1.08376037983\n",
      "train loss:0.948283912545\n",
      "train loss:0.936146286426\n",
      "train loss:0.807800587749\n",
      "train loss:0.823280458139\n",
      "train loss:0.855587955301\n",
      "train loss:0.647602949491\n",
      "train loss:0.729258129157\n",
      "train loss:0.742166638627\n",
      "train loss:0.685726765057\n",
      "train loss:0.684743685355\n",
      "train loss:0.654615551113\n",
      "train loss:0.560001070371\n",
      "train loss:0.612003665896\n",
      "train loss:0.755629320678\n",
      "train loss:0.640315841357\n",
      "train loss:0.766571751954\n",
      "train loss:0.662528744159\n",
      "train loss:0.484922617426\n",
      "train loss:0.43872398886\n",
      "train loss:0.529707326926\n",
      "train loss:0.734733447064\n",
      "train loss:0.800711110282\n",
      "train loss:0.535094298135\n",
      "train loss:0.682570045664\n",
      "train loss:0.549870744251\n",
      "train loss:0.519888930759\n",
      "train loss:0.44627174826\n",
      "train loss:0.454275262177\n",
      "train loss:0.591273920102\n",
      "train loss:0.406097902844\n",
      "train loss:0.482135106755\n",
      "train loss:0.395660577978\n",
      "train loss:0.508883575809\n",
      "train loss:0.543662988705\n",
      "train loss:0.454142223516\n",
      "train loss:0.630319637539\n",
      "train loss:0.476135093618\n",
      "train loss:0.864662380493\n",
      "train loss:0.407447944594\n",
      "train loss:0.609113901292\n",
      "train loss:0.44860704353\n",
      "train loss:0.311345771896\n",
      "train loss:0.543060327604\n",
      "train loss:0.410456717434\n",
      "train loss:0.559490532989\n",
      "train loss:0.34368861591\n",
      "train loss:0.49134542026\n",
      "train loss:0.437646555532\n",
      "train loss:0.344049386655\n",
      "train loss:0.339159703413\n",
      "train loss:0.349775981491\n",
      "train loss:0.541784918048\n",
      "train loss:0.374952175716\n",
      "train loss:0.378212964427\n",
      "train loss:0.40712333136\n",
      "train loss:0.548094328594\n",
      "train loss:0.41034170657\n",
      "train loss:0.45522066121\n",
      "train loss:0.322954624809\n",
      "train loss:0.479626934061\n",
      "train loss:0.355049773832\n",
      "train loss:0.38648911462\n",
      "train loss:0.448212420753\n",
      "train loss:0.386118325371\n",
      "train loss:0.439385763305\n",
      "train loss:0.517832114176\n",
      "train loss:0.456350595573\n",
      "train loss:0.565305581841\n",
      "train loss:0.514710878304\n",
      "train loss:0.361933724275\n",
      "train loss:0.491986292106\n",
      "train loss:0.477657170504\n",
      "train loss:0.239943963688\n",
      "train loss:0.419000807921\n",
      "train loss:0.504711961847\n",
      "train loss:0.39411187626\n",
      "train loss:0.54206233803\n",
      "train loss:0.566949094746\n",
      "train loss:0.36390688599\n",
      "train loss:0.312598759327\n",
      "train loss:0.453695782272\n",
      "train loss:0.298027500892\n",
      "train loss:0.394330744857\n",
      "train loss:0.563209864278\n",
      "train loss:0.354077458494\n",
      "train loss:0.394582113006\n",
      "train loss:0.351529284332\n",
      "train loss:0.33592100065\n",
      "train loss:0.455899242888\n",
      "train loss:0.417024504082\n",
      "train loss:0.4881345891\n",
      "train loss:0.312608315061\n",
      "train loss:0.467744761557\n",
      "train loss:0.525369554169\n",
      "train loss:0.447762511877\n",
      "train loss:0.469167744036\n",
      "train loss:0.279099123895\n",
      "train loss:0.358472338742\n",
      "train loss:0.4532827578\n",
      "train loss:0.442363201177\n",
      "train loss:0.438812006647\n",
      "train loss:0.376810880148\n",
      "train loss:0.285318461841\n",
      "train loss:0.339036194553\n",
      "train loss:0.316817879043\n",
      "train loss:0.172930553999\n",
      "train loss:0.305268427223\n",
      "train loss:0.304618898337\n",
      "train loss:0.497595204751\n",
      "train loss:0.412801406441\n",
      "train loss:0.297678987757\n",
      "train loss:0.229894481344\n",
      "train loss:0.570481248467\n",
      "train loss:0.239873399403\n",
      "train loss:0.508203969213\n",
      "train loss:0.29273554711\n",
      "train loss:0.440325950267\n",
      "train loss:0.266293530474\n",
      "train loss:0.248108571962\n",
      "train loss:0.226651310489\n",
      "train loss:0.371756424076\n",
      "train loss:0.39398096475\n",
      "train loss:0.289986041599\n",
      "train loss:0.307374559395\n",
      "train loss:0.346497452608\n",
      "train loss:0.269750489319\n",
      "train loss:0.541435912928\n",
      "train loss:0.339720634463\n",
      "train loss:0.428354179237\n",
      "train loss:0.23464805382\n",
      "train loss:0.599440305754\n",
      "train loss:0.313521840954\n",
      "train loss:0.346328249115\n",
      "train loss:0.390515901305\n",
      "train loss:0.425535544886\n",
      "train loss:0.30706580518\n",
      "train loss:0.285608581255\n",
      "train loss:0.225618362306\n",
      "train loss:0.184783981525\n",
      "train loss:0.391984533293\n",
      "train loss:0.300750522123\n",
      "train loss:0.297121419073\n",
      "train loss:0.290971855088\n",
      "train loss:0.378633194091\n",
      "train loss:0.314132661244\n",
      "train loss:0.237883598391\n",
      "train loss:0.243235622441\n",
      "train loss:0.428613888786\n",
      "train loss:0.350583064037\n",
      "train loss:0.241615215282\n",
      "train loss:0.281285201875\n",
      "train loss:0.345850884467\n",
      "train loss:0.313030150497\n",
      "train loss:0.314461601504\n",
      "train loss:0.345230916727\n",
      "train loss:0.248745404844\n",
      "train loss:0.356713135737\n",
      "train loss:0.23593112522\n",
      "train loss:0.328692143838\n",
      "train loss:0.308063790494\n",
      "train loss:0.404596873574\n",
      "train loss:0.181175006776\n",
      "train loss:0.221539918191\n",
      "train loss:0.217009919596\n",
      "train loss:0.557796727278\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 用于导入父目录中的文件的设置import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from simple_convnet import SimpleConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "#导入数据\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 在处理速度慢的情况下减少数据\n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 保存参数\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# 绘制图表\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
